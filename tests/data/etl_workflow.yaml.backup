name: "Practical ETL Workflow"
start_task: "create_network"

variables:
  # This network name ensures all containers can talk to each other
  network: "highway-etl-net"
  postgres_host: "highway_postgres"
  postgres_pass: "mysecretpassword"
  postgres_db: "todos"
  redis_host: "highway_redis"
  api_url: "https://jsonplaceholder.typicode.com/todos/199"

tasks:
  # --- 1. SETUP ---
  create_network:
    task_id: "create_network"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      # '|| true' makes this command idempotent.
      - "docker network create {{ variables.network }} || true"
    dependencies: []
    result_key: "network_setup"

  start_postgres:
    task_id: "start_postgres"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      - >
        docker run -d --rm --name {{ variables.postgres_host }}
        --network {{ variables.network }}
        -e POSTGRES_PASSWORD={{ variables.postgres_pass }}
        -e POSTGRES_DB={{ variables.postgres_db }}
        postgres:15-alpine
    dependencies:
      - "create_network"
    result_key: "postgres_cid"

  start_redis:
    task_id: "start_redis"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      - >
        docker run -d --rm --name {{ variables.redis_host }}
        --network {{ variables.network }}
        redis:7-alpine
    dependencies:
      - "create_network"
    result_key: "redis_cid"

  # --- 2. EXTRACT ---
  fetch_todo:
    task_id: "fetch_todo"
    operator_type: "task"
    runtime: "python"
    function: "fetch.get"
    args:
      - "{{ variables.api_url }}"
    dependencies: [] # This can run in parallel with setup
    result_key: "todo_data"
    # This now stores the RAW JSON STRING, e.g.:
    # '{"userId": 10, "id": 199, ...}'

  # --- 3. LOAD 1 (to Postgres) ---
  wait_for_postgres:
    task_id: "wait_for_postgres"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      - >
        docker run --rm --network {{ variables.network }} postgres:15-alpine
        /bin/sh -c "until pg_isready -h {{ variables.postgres_host }}
        -U postgres; do echo 'Waiting for Postgres...'; sleep 1; done"
    dependencies:
      - "start_postgres"
    result_key: "postgres_ready"

  # ADJUSTED TASK: This now uses a Python container to parse the JSON
  # string and execute the SQL, which is far more robust.
  insert_data:
    task_id: "insert_data"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      # We run a Python container, install psycopg2, parse the JSON,
      # and then run the SQL.
      # Note the '\"' and '\\\"' escaping for the inner script.
      - >
        docker run --rm --network {{ variables.network }} python:3.10-slim /bin/sh -c
        "\"pip install -q psycopg2-binary && python3 -c \\\"
        import os, psycopg2, json;
        
        # 1. Parse the JSON string from the previous task
        todo_str = '''{{ results.todo_data }}''';
        todo_data = json.loads(todo_str);
        
        # 2. Connect to the DB
        conn = psycopg2.connect(host='{{ variables.postgres_host }}', dbname='{{ variables.postgres_db }}', user='postgres', password='{{ variables.postgres_pass }}');
        cur = conn.cursor();
        
        # 3. Create table and insert
        cur.execute('CREATE TABLE IF NOT EXISTS todos (id INT PRIMARY KEY, title TEXT, completed BOOLEAN)');
        cur.execute(
            'INSERT INTO todos (id, title, completed) VALUES (%s, %s, %s) ON CONFLICT (id) DO NOTHING',
            (todo_data['id'], todo_data['title'], todo_data['completed'])
        );
        conn.commit();
        cur.close();
        conn.close();
        print(f'Inserted ID: {todo_data['id']}');
        \\\"\""
    dependencies:
      - "wait_for_postgres"
      - "fetch_todo"
    result_key: "insert_ok"

  # --- 4. TRANSFORM & LOAD 2 (Postgres -> Redis) ---
  # ADJUSTED TASK: This also parses the JSON string to get the ID.
  process_and_move_data:
    task_id: "process_and_move_data"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      - >
        docker run --rm --network {{ variables.network }} python:3.10-slim /bin/sh -c
        "\"pip install -q psycopg2-binary redis && python3 -c \\\"
        import os, psycopg2, redis, json;
        
        # 1. Parse the JSON string
        todo_str = '''{{ results.todo_data }}''';
        todo_data = json.loads(todo_str);
        todo_id = todo_data['id'];

        # 2. Connect to Postgres and fetch title
        conn = psycopg2.connect(host='{{ variables.postgres_host }}', dbname='{{ variables.postgres_db }}', user='postgres', password='{{ variables.postgres_pass }}');
        cur = conn.cursor();
        cur.execute('SELECT title FROM todos WHERE id = %s', (todo_id,));
        title = cur.fetchone()[0];
        cur.close();
        conn.close();
        
        # 3. Connect to Redis and set title
        r = redis.Redis(host='{{ variables.redis_host }}', port=6379, db=0);
        r.set(f'todo:{todo_id}:title', title);
        print(f'Moved title to Redis: {title}');
        \\\"\""
    dependencies:
      - "insert_data"
      - "start_redis"
    result_key: "process_output"

  # --- 5. VALIDATE ---
  # ADJUSTED TASK: This also parses the JSON string to get the ID.
  read_from_redis:
    task_id: "read_from_redis"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      # We need the ID here too, so we have to parse the JSON string
      # just to build the redis key. We'll use shell tools for this.
      - >
        docker run --rm --network {{ variables.network }} redis:7-alpine
        /bin/sh -c "TODO_ID=$(echo '{{ results.todo_data }}' | grep -o '\"id\": *[0-9]*' | cut -d ':' -f 2 | tr -d ' ');
        redis-cli -h {{ variables.redis_host }} GET todo:$TODO_ID:title"
    dependencies:
      - "process_and_move_data"
    result_key: "final_title"

  # --- 6. CLEANUP ---
  stop_services:
    task_id: "stop_services"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      - "docker stop {{ variables.postgres_host }} {{ variables.redis_host }}"
    dependencies:
      - "read_from_redis"
    result_key: "stop_ok"

  cleanup_network:
    task_id: "cleanup_network"
    operator_type: "task"
    runtime: "python"
    function: "command.run"
    args:
      - "docker network rm {{ variables.network }}"
    dependencies:
      - "stop_services"
    result_key: "cleanup_ok"
