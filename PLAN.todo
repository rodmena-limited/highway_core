# Highway Core Redis Integration Plan

## Overview
This document outlines the plan to integrate Redis into Highway Core to improve memory efficiency and resilience, as per the requirements.

## Goals
1. Reduce local memory usage by utilizing Redis for state management
2. Improve resilience by leveraging Redis features
3. Maintain existing functionality while adding Redis support
4. Ensure all tests continue to pass without significant changes
5. Update GitHub Actions to support Redis for testing

## Implementation Steps

### Phase 1: Add Redis Dependencies and Configuration
1. Add `redis` to project dependencies in `pyproject.toml`
2. Create Redis persistence manager class implementing the same interface as current SQL persistence
3. Add Redis configuration handling (from environment variables)
4. Create Redis connection utility functions

### Phase 2: Redis Persistence Manager Implementation
1. Implement a Redis-based persistence manager that implements the PersistenceManager interface
2. Implement methods for:
   - start_workflow / complete_workflow / fail_workflow
   - start_task / complete_task / fail_task
   - save_workflow_state / load_workflow_state
   - save_task_result / save_task_execution
   - mark_task_completed
   - save_task / save_task_if_not_exists
   - close

### Phase 3: Update Engine to Support Redis
1. Modify the engine to accept Redis configuration
2. Allow selection between SQL and Redis persistence managers
3. Update constructor to initialize Redis persistence when needed

### Phase 4: Update Orchestrator State Management
1. Modify state loading/saving to use Redis when available
2. Ensure WorkflowState can work with Redis-backed data
3. Update state resolution and templating to work with Redis

### Phase 5: Environment Configuration
1. Add Redis credentials to .env or test.env for local development
2. Update GitHub Actions workflow to include Redis service
3. Add Redis connection parameters to test configuration

### Phase 6: Testing and Validation
1. Run existing tests to ensure no regressions
2. Test new Redis functionality
3. Run pipeline workflows to ensure they continue to pass
4. Add specific tests for Redis functionality

## Detailed Technical Implementation

### Redis Persistence Manager
- Key structure:
  - `workflow:{workflow_id}:state` → JSON serialized WorkflowState
  - `workflow:{workflow_id}:completed_tasks` → Set of task IDs
  - `workflow:{workflow_id}:results` → Hash of task_id:result_key:result_value
  - `workflow:{workflow_id}:memory` → Hash of memory_key:memory_value
  - `workflow:{workflow_id}:tasks` → Hash of task_id:task_data
  - `workflow:{workflow_id}:task:{task_id}:result` → JSON serialized task result

### Configuration
- Support Redis via environment variables: REDIS_HOST, REDIS_PORT, REDIS_PASSWORD, REDIS_DB
- Default to localhost:6379 when not specified

### Backward Compatibility
- Keep SQL persistence as an option for those who prefer it
- Default behavior should remain unchanged unless Redis is explicitly configured
- Provide clear configuration documentation

## Risks and Mitigation
1. **Data Consistency**: Redis is primarily an in-memory store, so ensure proper persistence settings are used
2. **Network Latency**: Redis network calls might be slower than local memory access, but this is offset by reduced memory usage
3. **Test Compatibility**: Ensure all existing tests continue to work with minimal changes

## Success Criteria
1. All existing tests pass without significant changes
2. Pipeline workflows run successfully
3. Redis integration works as expected
4. Memory usage is reduced compared to full in-memory approach
5. GitHub Actions workflow includes Redis for testing