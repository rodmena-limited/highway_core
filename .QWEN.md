# Highway Core: Technical Specification & Implementation

## Project Overview

Highway Core is a sophisticated workflow engine that enables the definition, execution, and management of complex workflows through YAML-based configuration. Built with resilience and scalability in mind, it supports persistence, conditional flows, loops, and parallel execution.

## Architecture

### Core Components

#### 1. Engine Layer
The engine provides the main execution framework with the following key modules:

- **engine.py**: Main entry point that orchestrates workflow execution
- **orchestrator.py**: Manages workflow execution flow and state transitions
- **state.py**: Handles workflow state management and variable tracking
- **models.py**: Pydantic-based data models for workflow validation
- **resource_manager.py**: Manages computational resources and bulkhead isolation
- **sub_workflow_runner.py**: Handles nested workflow execution

#### 2. Operator Handlers
Each operator type has dedicated handlers in the `operator_handlers` directory:
- **task_handler.py**: Executes function-based tasks
- **condition_handler.py**: Manages conditional branching logic
- **parallel_handler.py**: Handles parallel task execution
- **wait_handler.py**: Manages wait/sleep operations
- **while_handler.py**: Implements while loop logic
- **foreach_handler.py**: Handles iteration over collections

#### 3. Execution Layer
The `executors` directory provides different execution strategies:
- **base.py**: Base execution interface
- **docker.py**: Docker-based execution environment
- **local_python.py**: Local Python execution environment

#### 4. Persistence Layer
The `persistence` directory implements various storage strategies:
- **manager.py**: Persistence interface definition
- **sql_persistence.py**: SQLAlchemy-based database persistence
- **database_manager.py**: Database operations layer
- **models.py**: SQLAlchemy ORM models
- **db_storage.py**: File-based storage (fallback)
- **file_storage.py**: Alternative file-based persistence

#### 5. Tools Layer
The `tools` directory provides various utility functions and services:
- **registry.py**: Tool registration and discovery system
- **memory.py**: In-memory data operations
- **log.py**: Logging operations
- **fetch.py**: HTTP/Network operations
- **command.py**: Command execution
- **ansible.py**: Ansible integration (planned)
- **bulkhead.py**: Bulkhead pattern implementation for isolation

#### 6. Utilities
The `utils` directory contains helper functions and constants.

## Key Features Implementation

### 1. Workflow Definition and Validation
- Workflows are defined in YAML format with strict Pydantic validation
- Supports variables, dependencies, and result storage
- Task execution order determined through topological sorting
- Multiple operator types: task, condition, parallel, wait, while, foreach

### 2. Bulkhead Pattern Implementation
- Isolates different workflows to prevent resource contention
- Configurable limits on concurrent calls, queue sizes, and timeouts
- Failure and success thresholds for circuit breaker functionality
- Automatic cleanup and resource management

### 3. Persistence and Resumability
- SQLAlchemy-based database persistence
- Automatic saving of workflow state after each task execution
- Ability to resume workflows from saved states
- Support for multiple database formats through SQLAlchemy abstractions

### 4. Parallel Execution Support
- Task-level parallelism with dependency tracking
- Bulkhead isolation for concurrent task execution
- Result aggregation from parallel branches

### 5. Conditional Logic and Loops
- Support for conditional branching using expressions
- While loops with configurable conditions
- ForEach loops for iteration over collections

### 6. Enhanced Error Handling and Resilience
- Improved error detection and logging in the orchestrator
- Better handling of circular dependencies and unmet task dependencies
- More robust task execution with error persistence
- Graceful failure handling that marks tasks as failed in persistence
- Comprehensive error reporting for debugging workflow issues

## Core Architecture Patterns

### 1. Dependency Inversion Principle
- High-level modules depend on abstractions (persistence manager interface)
- Lower-level modules implement specific persistence strategies
- Enables easy swapping of persistence mechanisms

### 2. Single Responsibility Principle
- Each module has a well-defined responsibility
- Operator handlers manage specific operator types
- Executors handle execution environments
- Tools provide specific functionality

### 3. Bulkhead Pattern
- Isolates resources to prevent cascading failures
- Limits concurrent execution to prevent resource exhaustion
- Enables graceful degradation under load

## Technical Implementation Details

### Data Flow
1. Workflow YAML is loaded and validated using Pydantic models
2. Workflow state is initialized and loaded from persistence if available
3. Tasks are scheduled based on dependencies and current execution state
4. Tasks are executed with bulkhead isolation
5. Results are saved to persistence after each execution
6. Workflow continues until all tasks are completed or failure occurs

### State Management
- Current state, results, and variables are maintained in memory
- State is persisted after each task completion
- Supports workflow resumption from saved state
- Handles variable interpolation and result references

### Error Handling
- Comprehensive error handling at multiple levels
- Circuit breaker pattern for fault tolerance
- Graceful degradation when persistence or external services fail
- Detailed logging for debugging and monitoring

## Database Schema

The persistence layer uses SQLAlchemy to manage workflow data:

- **Workflow table**: Stores workflow metadata (ID, name, status, timestamps)
- **Task table**: Stores individual task information (ID, workflow_id, operator_type, status, results)
- **Variable table**: Stores workflow variables and their values
- **Result table**: Stores task execution results

## Testing Strategy

The project includes comprehensive test coverage:
- Unit tests for individual components
- Integration tests for workflow execution
- Database workflow tests with SQLAlchemy verification
- Parallel execution tests
- Type checking with mypy

## Type Safety

- Uses Pydantic for runtime validation
- Static type checking with mypy
- Rich type annotations throughout the codebase
- Proper handling of optional values and union types

## CLI Implementation

The command-line interface provides:
- Simple workflow execution from YAML files
- Optional run ID specification for persistence
- Verbose logging options
- Proper error handling and exit codes

## Development Practices

- Modern Python (3.10+)
- Poetry-style pyproject.toml configuration
- Strict type checking with mypy
- Comprehensive unit test coverage
- Proper logging throughout the system
- Modular architecture with clear interfaces
- Git-flow based development model